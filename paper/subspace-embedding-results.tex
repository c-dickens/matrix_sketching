%!TEX root = sketching-convex-ols.tex

As outlined in Section \ref{sec: preliminaries} the key quantity that we would
like to understand is the subspace embedding.
The central questions we seek to answer are: (1) whether the time complexity
in practise matches the theory, (2) how large should the projection
dimension be in order to obtain small error (3) the CountSketch
theoretically requires a larger projection to obtain the subspace embedding
property, is this reflected in practise?

\noindent\textbf{Time Complexity compared to sparsity.} The CountSketch takes
$O(\nnz{A})$ time to construct a subspace embedding
whereas the SRHT requires $O(nd \log n)$.
Although the SRHT does not scale with the sparsity of the data, for the
practitioner it
will be of interest to know where, if any, there is a threshold at which one of
the transforms is preferable from the perspective of time cost.
To test this claim we generated random matrices of size $n$ varying from
$10000, 25000, 50000, 100000$ and $d$ ranging from $10,50,100,500,1000$
with a \textit{density} parameter $\rho$ which was varied from 0 to 1.
A projection dimension of $5d$ was chosen for the summarisation as this offered
a good tradeoff between compute time and accuracy which will be discussed in the
succeeding section.
The density is the fraction of nonzeros entries in the matrix out of a possible
$nd$.
Only the CountSketch and SRHT are tested because the explicit matrix
multiplication for the Gaussian sketch is exceedingly high which even
for moderately sized inputs will be prohibitive compared to the other two methods.
As seen in Figure \ref{fig: summary-time-100000}, both transforms scale
consistently with the theory: the CountSketch has increased time to compute the
summary as the density of the data increases and the SRHT is generally stable as
the density varies.
The key point to take away is that the CountSketch is generally \textit{an order
of magnitude faster} to compute the embedding demonstrating that as $n$ grows
to be significantly larger than $d$, this saving could be vast.
Interestingly, our implementations do not show a cross over point for corresponding
settings of the parameters i.e for a fixed $(n,d,m)$ triple the time to compute the
CountSketch summary is always significantly less than that for
the SRHT summary.
This behaviour is consistent across each of the setup values so only those for
the setting $(n,d) = (10000, \cdot)$ are given here.
In addition, the time benefit of using the CountSketch over the SRHT is reflected
on the real datasets as well with the results given in Table
\ref{table: real-data-subspace-embedding}
where roughly equal distortions are found at a fraction of the time cost.
For the `tall-skinny' matrices the CountSketch is found again with at least a
factor of 10 less time but for the wider matrices the SRHT times out in our
implementation.

\begin{figure}
  \centering
\includegraphics[scale=0.75,keepaspectratio]{summary_time_density_10000}
        \caption{$n=100000$}
        \label{fig: summary-time-100000}
\end{figure}





% \begin{figure}
%   \includegraphics[scale=0.25,keepaspectratio]{summary_time_density_10000}
%   \caption{Time to compute summaries for $n=100000$, $d$ given in legend next
%   to sketch name and sketch dimension $m = 5d$ used.} \label{fig: summary-times-vs-sparsity}
% \end{figure}




% \begin{figure}
%     \centering
%     \begin{subfigure}[b]{0.49\textwidth}
%         \includegraphics[scale=0.45,keepaspectratio]{summary_time_density_10000}
%         \caption{$n=100000$}
%         \label{fig: summary-time-100000}
%     \end{subfigure}
%     \begin{subfigure}[b]{0.49\textwidth}
%         \includegraphics[scale=0.425,keepaspectratio]{distortion_vs_cols}
%         \caption{Distortion compared to number of columns}
%         \label{fig: distortion-columns}
%     \end{subfigure}
%     ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
%       %(or a blank line to force the subfigure onto a new line)
% \end{figure}

% Please add the following required packages to your document preamble:
%

\begin{table}[ht]
\centering
\begin{adjustbox}{width=1\textwidth}
\small

\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}
  \hline
\multirow{2}{*}{Dataset} & \multicolumn{3}{c|}{CountSketch (time)} & \multicolumn{3}{c}{SRHT (time)} & \multicolumn{3}{c|}{CountSketch (error)} & \multicolumn{3}{c|}{SRHT (error)} \\
                        &     $2d$       &  $5d$            & $10d$          & $2d$          & $5d$        & $10d$         &     $2d$       &  $5d$          &   $10d$         &  $2d$          & $5d$         & $10d$  \\
\hline
YearPredictionsMSD                         &    0.116         &   0.110          &  0.112          &  2.56         &  2.51        &   2.51        &  0.012           &   0.005          &    0.003           &   0.019        &   0.005        &  0.002         \\
Rail2586            &  0.222           &  0.365           &  0.758             &  -         & -         & -           & 0.043             &  0.017             &  0.009            & -          & -           & -           \\
California Housing     &   0.005          &  0.002           &   0.002          &  0.015         &  0.014        & 0.015          &   0.024          &  0.007           & 0.017       & 0.084          & 0.043         & 0.018 \\
US Census    &            &           &          &      &         &            &            &              &         &          &  &        \\
\hline
\end{tabular}
\end{adjustbox}
\caption{Comparison of CountSketch and SRHT on real datasets}
\label{table: real-data-subspace-embedding}
\end{table}


\noindent\textbf{Sufficient Sketching Dimension}
Although our theory shows that a subspace embedding is sufficient to use a random
projection within the IHS scheme, we first need to understand how large the
sampling factor $\gamma$ must be relative to $d$ in order to obtain a subspace
embedding.
The constants within the $O(\cdot)$ term must be understood to ensure that $SA$
is of full rank and we invesitgate how this changes depending on the aspect
ratio of the matrix.
For this set of experiments we fix $n$ and then generate a selection of matrices
which range from `tall-and-skinny' to `fat' matrices by choosing $d$ to range
from roughly $0.05n$ to $0.5n$ over a variety of distributions.
The results from choosing matrices whose entries are standard normal are given
in Figure ...
The value of $\eps$ was then measured: this is referred to as the \textit{
distortion} and is the error induced by the approximate matrix product
computation $\|A^T A - A^T S^T S A \|_F/\|A^TA\|_F$.
In addition, we also measure the rank of the returned matrix $SA$ as it must
be preserved for a subspace embedding.
The plots indicate that in general, the distortion induced by the CountSketch is
comparable with at least one of the Gaussian or SRHT sketches.
There are regimes in which, purely from a distortion perspective, one of the
sketches is consistently about a constant factor better (namely the SRHT on the
Gaussian random matrices) but it seems that the distortion is similar for each
of the sketches tested.

The CountSketch achieves comparable distortion to the other methods and constructs
an embedding in vastly less time, however, there is a price to pay for this
computational benefit.
As the aspect ratio increases the number of rank deficient embeddings also
grows; taking $\gamma > 1.05$ is sufficient to ensure that rank is preserved
when $d/n=0.25$ yet the required sampling factor grows considerably with $d/n$.
When $d/n=0.375$ we need roughly $\gamma = 1.125$ for all of the embeddings to
preserve rank for the CountSketch but when $d/n = 0.5$ \textit{none} of the
tested sampling factors up to $\gamma=1.25$ returned a subspace embedding.
This failure of the CountSketch to accurately preserve rank at higher aspect
ratios highlights one deficiency it possesses compared to the other sketches.
Put simply, \textit{CountSketch is more sensitive to higher aspect ratios and
requires a higher sampling factor in this regime compared to the other
sketching methods.}
However, given that the sketches are designed for particularly tall and skinny
matrices, one could argue that CountSketch failing above $d/n = 0.375$ is in
fact not problematic: on all the test instance which fall into the tall-and-
skinny setup, CountSketch retains rank with comparable distortion.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{subspace_embedding_results/subspace_embedding_dimension_gaussian_2048_256.pdf}
        \caption{$d=256$}
        \label{fig: subspace-125e3-aspectratio}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{subspace_embedding_results/subspace_embedding_dimension_gaussian_2048_768.pdf}
        \caption{$d=375$}
        \label{fig: subspace-375e1-aspectratio}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
    %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{subspace_embedding_results/subspace_embedding_dimension_gaussian_2048_512.pdf}
        \caption{$d=512$}
        \label{fig: subspace-25e1-aspectratio}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{subspace_embedding_results/subspace_embedding_dimension_gaussian_2048_1024.pdf}
        \caption{$d=1024$}
        \label{fig: subspace-5e1-aspectratio}
    \end{subfigure}
    \caption{Distortion compared to sampling factor for various aspect ratios.
    Plotted are the mean results over 10 trials and a cross denotes when at least
    one trial has failed.
    The larger crosses indicate a higher number of failures with the largest
    crosses in Figure \ref{fig: subspace-5e1-aspectratio} for which CountSketch
    \textit{never} returned a full rank subspace embedding.}
    \label{fig: distortion-sampling-factor}
\end{figure}



\subsection{Extra}
The CountSketch is noticeably faster than the SRHT (and we assume
 faster
than the Gaussian transform due to the explicit matrix product), the benefits
enjoyed by the time saving will become immaterial if the error induced by the
CountSketch is significantly higher.
In this experiment we test... and show that the subspace embedding error from
using the CountSketch is comparable to using both other methods.
There appears to be slightly more variation in the errors from using CountSketch
as opposed to the other methods and as such we need to check that this is not
prohibitive in the IHS model and this is explored in Section
\ref{sec: countsketch-ihs}.
